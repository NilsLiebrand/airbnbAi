{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12251642,"sourceType":"datasetVersion","datasetId":7719588},{"sourceId":12479618,"sourceType":"datasetVersion","datasetId":7715214}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Training the model","metadata":{}},{"cell_type":"code","source":"import os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n#    for filename in filenames:\n        #print(os.path.join(dirname, filename))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader, random_split\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.impute import SimpleImputer\nimport matplotlib.pyplot as plt\n\n#progress bar\nfrom tqdm import trange\nfrom tqdm import tqdm","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#torch.set_default_dtype(torch.float64)\n#torch.cuda.is_available(), torch.backends.cudnn.is_available(), torch.cuda.device_count(), torch.cuda.current_device()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"use_cuda = True\nuse_cuda = False if not use_cuda else torch.cuda.is_available()\ndevice = torch.device('cuda:0' if use_cuda else 'cpu')\ntorch.cuda.get_device_name(device) if use_cuda else 'cpu'\nprint('Using device', device)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Loading and preparing data","metadata":{}},{"cell_type":"code","source":"# Load and filter data\ndata = pd.read_csv(\"/kaggle/input/airbnbdata-barcelona/listing_data_lower_dimension.csv\")\ndata = data.select_dtypes(exclude=['object', 'string'])\ndata = data.drop(\"id\", axis=1)\n\n# Define target column\ntarget_clm = \"price\"\n\n# Drop rows with missing target\ndata = data.dropna(subset=[target_clm])\n\n# Create an imputer that fills NaNs with the mean of each column\nimputer = SimpleImputer(strategy='mean')\n\n# Fit the imputer on your data and transform it\ndata_imputed = imputer.fit_transform(data)\n\n# Convert back to DataFrame to keep column names\ndata = pd.DataFrame(data_imputed, columns=data.columns)  ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_size = 0.2\ntrain_df, test_df = train_test_split(data, test_size=test_size, random_state=42)\n\n# Normalization stats from training data\ntrain_mean = train_df.drop(target_clm, axis=1).mean().astype(np.float32).values\ntrain_std = train_df.drop(target_clm, axis=1).std().replace(0, 1).astype(np.float32).values\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Dataset","metadata":{}},{"cell_type":"code","source":"class TabularDataset(Dataset):\n    def __init__(self, df, target_clm, mean=None, std=None, normalize=True):\n        self.X = df.drop(target_clm, axis=1).to_numpy(dtype=np.float32)\n        self.y = df[target_clm].to_numpy(dtype=np.float32)\n        self.mean = mean\n        self.std = std\n        self.normalize = normalize\n\n    def __len__(self):\n        return len(self.X)\n\n    def __getitem__(self, idx):\n        x = self.X[idx]\n        if self.normalize and self.mean is not None and self.std is not None:\n            x = (x - self.mean) / self.std\n        return torch.tensor(x, dtype=torch.float32), torch.tensor(self.y[idx], dtype=torch.float32)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Datasets\ntrain_dataset_full = TabularDataset(train_df, target_clm, train_mean, train_std, normalize=True)\ntest_dataset = TabularDataset(test_df, target_clm, train_mean, train_std, normalize=True)\n\n# Split train/val\ntorch.manual_seed(0)\nval_ratio = 0.1\ntrain_dataset, val_dataset = random_split(train_dataset_full, [1 - val_ratio, val_ratio])\n\n# DataLoaders\nbatch_size = 128\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size)\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class LinearRegressionModel(nn.Module):\n    def __init__(self, input_dim):\n        super().__init__()\n        self.linear = nn.Linear(input_dim, 1, bias=True)\n\n    def forward(self, x):\n        return self.linear(x).squeeze()  # Squeeze to match target shape\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Device setup\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Instantiate model\ninput_dim = train_df.drop(target_clm, axis=1).shape[1]\nmodel = LinearRegressionModel(input_dim).to(device)\nmodel = model.float()\n# Loss and optimizer\ncriterion = nn.HuberLoss(delta=1.0)\n#criterion = nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Any NaN in features? \", np.isnan(data.drop(target_clm, axis=1).to_numpy()).any())\nprint(\"Any NaN in target? \", np.isnan(data[target_clm].to_numpy()).any())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train(dataloader, optimizer, model, loss_fn, device, master_bar):\n    model.train()\n    train_loss = 0.0\n    for batch in dataloader:\n        X, y = batch\n        X, y = X.to(device), y.to(device)\n\n        #Forward pass\n        optimizer.zero_grad()\n        outputs = model(X)\n        loss = loss_fn(outputs, y)\n\n        #Backward pass\n        loss.backward()\n        optimizer.step()\n\n        #calculate step quality\n        train_loss += loss.item()\n\n        master_bar.set_description(f\"Epoch {master_bar.n + 1} (Train)\")\n        master_bar.set_postfix(loss=f\"{loss.item():.3f}\")\n\n    return train_loss / len(dataloader)\n\n        ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def validate(dataloader, model, loss_fn, device, master_bar):\n    model.eval()\n    val_loss = 0\n\n    with torch.no_grad():\n        for batch in dataloader:\n            X, y = batch\n            X, y = X.to(device), y.to(device)\n\n            #validate\n            outputs = model(X)\n            loss = loss_fn(outputs, y)\n            val_loss += loss.item()\n\n            master_bar.set_description(f\"Epoch {master_bar.n + 1} (Validate)\")\n            master_bar.set_postfix(loss=f\"{loss.item():.3f}\")\n    \n    return val_loss / len(dataloader)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def run_training(model, optimizer, loss_function, device, num_epochs, train_dataloader, val_dataloader):\n    train_losses = []\n    val_losses = []\n\n    master_bar = trange(num_epochs, desc=\"Training Epochs\")\n    for epoch in master_bar:\n        train_loss = train(train_dataloader, optimizer, model, loss_function, device, master_bar)\n        val_loss = validate(val_dataloader, model, loss_function, device, master_bar)\n\n        train_losses.append(train_loss)\n        val_losses.append(val_loss)\n\n    return train_losses, val_losses","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def evaluate_model(model, dataloader, device):\n    model.eval()\n    model.to(device)\n    absolute_errors = []\n\n    with torch.no_grad():\n        for batch in dataloader:\n            # Assumes batch is (inputs, targets)\n            inputs, targets = batch\n            inputs, targets = inputs.to(device), targets.to(device)\n\n            predictions = model(inputs)\n            abs_errors = abs(predictions - targets)\n            \n            absolute_errors.extend(abs_errors.cpu().numpy())\n\n    return np.array(absolute_errors)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def plot_accuracy(errors, bins = 10, min_range = None, max_range = None):\n\n    if min_range is None:\n        min_range = min(errors)\n    if max_range is None:\n        max_range = max(errors)\n\n    counts, bin_edges = np.histogram(errors, bins=bins, range=(min_range, max_range))\n\n    percentages = 100 * counts / counts.sum()\n\n    bin_widths = bin_edges[1:] - bin_edges[:-1]\n\n    plt.bar(bin_edges[:-1], percentages, width = bin_widths, align = 'edge', edgecolor='black')\n    plt.xlabel(\"Absolute Error\")\n    plt.ylabel(\"Percentage (%)\")\n    plt.title(\"Percentage Distribution of Absolute Errors\")\n    \n    #plt.hist(errors, bins, range=(min_range, max_range), density=True)\n    plt.grid(True)\n    plt.show() ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def plotLosses(losses, title = \"\"):\n    plt.plot(range(1, len(losses) + 1),losses, label=title + \" loss\")\n    plt.legend()\n    plt.title(title + \" loss per epoch\")\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"epochs=30\n\nlosses = run_training(model, optimizer, criterion, device, epochs, train_loader, val_loader)\n\nplotLosses(losses[0], )","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#evaluate\nerr = evaluate_model(model, test_loader, device)\nplot_accuracy(err, bins = 5, min_range = 0, max_range = 300)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Testing other optimizers (Adagrad is very efficient for our sparse data)\noptimizer = torch.optim.Adagrad(model.parameters())\nepochs=30\n\nrun_training(model, optimizer, criterion, device, epochs, train_loader, val_loader)\nerr = evaluate_model(model, test_loader, device)\nplot_accuracy(err, bins = 5, min_range = 0, max_range = 300)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#true vs predicted graph\ndef plot_true_vs_predicted(model, dataloader, device):\n    model.eval()\n    model.to(device)\n    true_y = []\n    predicted_y = []\n\n    with torch.no_grad():\n        for batch in dataloader:\n            # Assumes batch is (inputs, targets)\n            tab, targets = batch\n            tab = tab.to(device)\n            targets = targets.to(device)\n\n            outputs = model(tab)\n            \n            # Move tensors to CPU and convert to numpy\n            predicted_y.append(outputs.cpu().numpy())\n            true_y.append(targets.cpu().numpy())\n\n    # Concatenate all batch results\n    true_y = np.concatenate(true_y)\n    predicted_y = np.concatenate(predicted_y)\n\n    plt.figure(figsize=(10, 6))\n    plt.scatter(true_y, predicted_y, alpha=0.5)\n    plt.plot([true_y.min(), true_y.max()], [true_y.min(), true_y.max()], 'k--', lw=2)  # Diagonal line\n    plt.xlabel(\"True Price\")\n    plt.ylabel(\"Predicted Price\")\n    plt.xlim(0, 500)  \n    plt.ylim(0, 500)\n    plt.title(\"True vs Predicted Price\")\n    plt.grid(True)\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_true_vs_predicted(model, test_loader, device)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}